{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_graph_lib import WordGraph, get_words, open_ipa_dict_representations_map, open_cmudict_representations_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD_LENGTH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_words('12dicts_words.txt')\n",
    "representations = None\n",
    "label_rep_function = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can also use different representations of words.\n",
    "# # Here, we will use IPA representations from this dictionary https://github.com/open-dict-data/ipa-dict\n",
    "# # There are also other choices like https://github.com/DanielSWolf/wiki-pronunciation-dict?tab=readme-ov-file, but they don't seem as complete\n",
    "# # It may be good to combine multiple sources\n",
    "# whitelisted_words = set(words)\n",
    "# ipa_dict_representations_map = open_ipa_dict_representations_map(whitelisted_words)\n",
    "# ipa_words = set(ipa_dict_representations_map.keys())\n",
    "# missed_words = whitelisted_words - ipa_words\n",
    "# print(f\"Found {len(ipa_words)} words in the IPA dictionary, missed {len(missed_words)} words\")\n",
    "\n",
    "# # Filter down the words and representations to only the ones we have in the IPA dictionary\n",
    "# ipa_words = []\n",
    "# ipa_representations = []\n",
    "# for word, representations in ipa_dict_representations_map.items():\n",
    "#     for representation in representations:\n",
    "#         ipa_words.append(word)  # Duplicate words are allowed as long as they have different representations\n",
    "#         ipa_representations.append(representation)\n",
    "\n",
    "# words = ipa_words\n",
    "# representations = ipa_representations\n",
    "\n",
    "# def label_rep_function(word, representation):\n",
    "#     return f\"{word} ({''.join(representation)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here we instead use the CMU pronunciation dictionary which uses ARPAbet instead of IPA\n",
    "# # ARPAbet is a simpler phonetic alphabet, but it is less accurate. The simplicity may be good for having more connected components\n",
    "# # The link is here https://github.com/cmusphinx/cmudict\n",
    "# whitelisted_words = set(words)\n",
    "# cmudict_representations_map = open_cmudict_representations_map(whitelisted_words)\n",
    "# cmudict_words = set(cmudict_representations_map.keys())\n",
    "# missed_words = whitelisted_words - cmudict_words\n",
    "# print(f\"Found {len(cmudict_words)} words in the CMU dictionary, missed {len(missed_words)} words\")\n",
    "\n",
    "# # Filter down the words and representations to only the ones we have in the CMU dictionary\n",
    "# cmudict_words = []\n",
    "# cmudict_representations = []\n",
    "# for word, representations in cmudict_representations_map.items():\n",
    "#     for representation in representations:\n",
    "#         cmudict_words.append(word)  # Duplicate words are allowed as long as they have different representations\n",
    "#         cmudict_representations.append(representation)\n",
    "\n",
    "# words = cmudict_words\n",
    "# representations = cmudict_representations\n",
    "\n",
    "# def label_rep_function(word, representation):\n",
    "#     return f\"{word} ({' '.join(representation)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing words of length 1\n",
      "\tNumber of words of length 1: 4\n",
      "\tRoot batch size: 125000 (500000 word pairs per batch)\n",
      "Processing words of length 2\n",
      "\tNumber of words of length 2: 61\n",
      "\tRoot batch size: 8196 (499956 word pairs per batch)\n",
      "Processing words of length 3\n",
      "\tNumber of words of length 3: 649\n",
      "\tRoot batch size: 770 (499730 word pairs per batch)\n",
      "Processing words of length 4\n",
      "\tNumber of words of length 4: 2446\n",
      "\tRoot batch size: 204 (498984 word pairs per batch)\n",
      "Processing words of length 5\n",
      "\tNumber of words of length 5: 4680\n",
      "\tRoot batch size: 106 (496080 word pairs per batch)\n",
      "Processing words of length 6\n",
      "\tNumber of words of length 6: 7352\n",
      "\tRoot batch size: 68 (499936 word pairs per batch)\n",
      "Processing words of length 7\n",
      "\tNumber of words of length 7: 9878\n",
      "\tRoot batch size: 50 (493900 word pairs per batch)\n",
      "Processing words of length 8\n",
      "\tNumber of words of length 8: 10466\n",
      "\tRoot batch size: 47 (491902 word pairs per batch)\n",
      "Processing words of length 9\n",
      "\tNumber of words of length 9: 9412\n",
      "\tRoot batch size: 53 (498836 word pairs per batch)\n",
      "Processing words of length 10\n",
      "\tNumber of words of length 10: 7569\n",
      "\tRoot batch size: 66 (499554 word pairs per batch)\n",
      "Processing words of length 11\n",
      "\tNumber of words of length 11: 5250\n",
      "\tRoot batch size: 95 (498750 word pairs per batch)\n",
      "Processing words of length 12\n",
      "\tNumber of words of length 12: 3383\n",
      "\tRoot batch size: 147 (497301 word pairs per batch)\n",
      "Processing words of length 13\n",
      "\tNumber of words of length 13: 1885\n",
      "\tRoot batch size: 265 (499525 word pairs per batch)\n",
      "Processing words of length 14\n",
      "\tNumber of words of length 14: 891\n",
      "\tRoot batch size: 561 (499851 word pairs per batch)\n",
      "Processing words of length 15\n",
      "\tNumber of words of length 15: 434\n",
      "\tRoot batch size: 1152 (499968 word pairs per batch)\n",
      "Processing words of length 16\n",
      "\tNumber of words of length 16: 176\n",
      "\tRoot batch size: 2840 (499840 word pairs per batch)\n",
      "Processing words of length 17\n",
      "\tNumber of words of length 17: 84\n",
      "\tRoot batch size: 5952 (499968 word pairs per batch)\n",
      "Processing words of length 18\n",
      "\tNumber of words of length 18: 21\n",
      "\tRoot batch size: 23809 (499989 word pairs per batch)\n",
      "Processing words of length 19\n",
      "\tNumber of words of length 19: 10\n",
      "\tRoot batch size: 50000 (500000 word pairs per batch)\n",
      "Processing words of length 20\n",
      "\tNumber of words of length 20: 7\n",
      "\tRoot batch size: 71428 (499996 word pairs per batch)\n",
      "Processing words of length 21\n",
      "\tNumber of words of length 21: 2\n",
      "\tRoot batch size: 250000 (500000 word pairs per batch)\n",
      "Processing words of length 22\n",
      "\tNumber of words of length 22: 2\n",
      "\tRoot batch size: 250000 (500000 word pairs per batch)\n",
      "Processing insertions from words of length 1 to words of length 2\n",
      "\tFound 47 candidate insertion pairs\n",
      "\tFound 47 verified insertion pairs\n",
      "Processing insertions from words of length 2 to words of length 3\n",
      "\tFound 923 candidate insertion pairs\n",
      "\tFound 517 verified insertion pairs\n",
      "Processing insertions from words of length 3 to words of length 4\n",
      "\tFound 6680 candidate insertion pairs\n",
      "\tFound 2608 verified insertion pairs\n",
      "Processing insertions from words of length 4 to words of length 5\n",
      "\tFound 18677 candidate insertion pairs\n",
      "\tFound 5123 verified insertion pairs\n",
      "Processing insertions from words of length 5 to words of length 6\n",
      "\tFound 22668 candidate insertion pairs\n",
      "\tFound 5135 verified insertion pairs\n",
      "Processing insertions from words of length 6 to words of length 7\n",
      "\tFound 23072 candidate insertion pairs\n",
      "\tFound 5683 verified insertion pairs\n",
      "Processing insertions from words of length 7 to words of length 8\n",
      "\tFound 17395 candidate insertion pairs\n",
      "\tFound 4926 verified insertion pairs\n",
      "Processing insertions from words of length 8 to words of length 9\n",
      "\tFound 9688 candidate insertion pairs\n",
      "\tFound 3598 verified insertion pairs\n",
      "Processing insertions from words of length 9 to words of length 10\n",
      "\tFound 5581 candidate insertion pairs\n",
      "\tFound 2979 verified insertion pairs\n",
      "Processing insertions from words of length 10 to words of length 11\n",
      "\tFound 2885 candidate insertion pairs\n",
      "\tFound 1945 verified insertion pairs\n",
      "Processing insertions from words of length 11 to words of length 12\n",
      "\tFound 1509 candidate insertion pairs\n",
      "\tFound 1166 verified insertion pairs\n",
      "Processing insertions from words of length 12 to words of length 13\n",
      "\tFound 696 candidate insertion pairs\n",
      "\tFound 574 verified insertion pairs\n",
      "Processing insertions from words of length 13 to words of length 14\n",
      "\tFound 366 candidate insertion pairs\n",
      "\tFound 321 verified insertion pairs\n",
      "Processing insertions from words of length 14 to words of length 15\n",
      "\tFound 140 candidate insertion pairs\n",
      "\tFound 126 verified insertion pairs\n",
      "Processing insertions from words of length 15 to words of length 16\n",
      "\tFound 64 candidate insertion pairs\n",
      "\tFound 52 verified insertion pairs\n",
      "Processing insertions from words of length 16 to words of length 17\n",
      "\tFound 40 candidate insertion pairs\n",
      "\tFound 34 verified insertion pairs\n",
      "Processing insertions from words of length 17 to words of length 18\n",
      "\tFound 7 candidate insertion pairs\n",
      "\tFound 7 verified insertion pairs\n",
      "Processing insertions from words of length 18 to words of length 19\n",
      "\tFound 3 candidate insertion pairs\n",
      "\tFound 3 verified insertion pairs\n",
      "Processing insertions from words of length 19 to words of length 20\n",
      "\tFound 0 candidate insertion pairs\n",
      "\tFound 0 verified insertion pairs\n",
      "Processing insertions from words of length 20 to words of length 21\n",
      "\tFound 1 candidate insertion pairs\n",
      "\tFound 1 verified insertion pairs\n",
      "Processing insertions from words of length 21 to words of length 22\n",
      "\tFound 1 candidate insertion pairs\n",
      "\tFound 1 verified insertion pairs\n",
      "Symbols: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "if MAX_WORD_LENGTH:\n",
    "    allowed_indices = [i for i, word in enumerate(words) if len(word) <= MAX_WORD_LENGTH]\n",
    "    processed_words = [words[i] for i in allowed_indices]\n",
    "    processed_representations = [representations[i] for i in allowed_indices]\n",
    "else:\n",
    "    processed_words = words\n",
    "    processed_representations = representations\n",
    "word_graph = WordGraph(processed_words, representations=processed_representations, label_rep_func=label_rep_function)\n",
    "\n",
    "print(f\"Symbols: {word_graph.symbol_to_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disconnected components: 26504\n",
      "Number of disconnected components with more than 2 words: 3024\n",
      "Number of disconnected components with more than 5 words: 563\n"
     ]
    }
   ],
   "source": [
    "disconnected_components = word_graph.find_disconnected_components()\n",
    "print(f\"Number of disconnected components: {len(disconnected_components)}\")\n",
    "print(f\"Number of disconnected components with more than 2 words: {len([comp for comp in disconnected_components if len(comp) > 2])}\")\n",
    "print(f\"Number of disconnected components with more than 5 words: {len([comp for comp in disconnected_components if len(comp) > 5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameter of the graph: 42\n",
      "Path: hammerings, hammering, hampering, pampering, papering, capering, catering, cantering, bantering, battering, bettering, fettering, festering, pestering, petering, peering, peeing, seeing, sewing, swing, sing, sine, mine, mire, mere, metre, metred, metered, petered, pestered, festered, fettered, bettered, battered, bantered, cantered, catered, capered, papered, pampered, hampered, hammered, yammered\n"
     ]
    }
   ],
   "source": [
    "path, diameter = word_graph.find_diameter()\n",
    "str_path = word_graph.path_to_label(path)\n",
    "print(f\"Diameter of the graph: {diameter}\")\n",
    "print(f\"Path: {', '.join(str_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path from cat to orange\n",
      "Path length: 5\n",
      "Path: cat, can, ran, rang, range, orange\n"
     ]
    }
   ],
   "source": [
    "# Now from cat to orange\n",
    "# Find the nodes\n",
    "start_node = 'cat'\n",
    "end_node = 'orange'\n",
    "\n",
    "print(f\"Shortest path from {start_node} to {end_node}\")\n",
    "path, path_length, _ = word_graph.bfs(start_node, end_node)\n",
    "if path is None:\n",
    "    print(\"No path found\")\n",
    "else:\n",
    "    str_path = word_graph.path_to_label(path)\n",
    "    print(f\"Path length: {path_length}\")\n",
    "    print(f\"Path: {', '.join(str_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DOT file\n",
    "dot_string = word_graph.to_dot()\n",
    "with open('word_graph.dot', 'w') as f:\n",
    "    f.write(dot_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
